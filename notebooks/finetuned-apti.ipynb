{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T01:52:00.573574Z","iopub.status.busy":"2024-09-25T01:52:00.573215Z","iopub.status.idle":"2024-09-25T01:52:02.262996Z","shell.execute_reply":"2024-09-25T01:52:02.262201Z","shell.execute_reply.started":"2024-09-25T01:52:00.573537Z"},"trusted":true},"outputs":[],"source":["from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    pipeline\n",")\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from datasets import load_dataset, Dataset\n","from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    prepare_model_for_kbit_training,\n","    PeftModel\n",")\n","import torch\n","from trl import SFTTrainer, SFTConfig"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T01:52:02.264533Z","iopub.status.busy":"2024-09-25T01:52:02.264191Z","iopub.status.idle":"2024-09-25T01:52:02.268974Z","shell.execute_reply":"2024-09-25T01:52:02.267860Z","shell.execute_reply.started":"2024-09-25T01:52:02.264482Z"},"trusted":true},"outputs":[],"source":["PAD_TOKEN = \"<|pad|>\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T01:52:02.273624Z","iopub.status.busy":"2024-09-25T01:52:02.272887Z","iopub.status.idle":"2024-09-25T01:52:02.308084Z","shell.execute_reply":"2024-09-25T01:52:02.307054Z","shell.execute_reply.started":"2024-09-25T01:52:02.273589Z"},"trusted":true},"outputs":[],"source":["class Finetune():\n","    def __init__(\n","            self,\n","            trainingData: str,\n","            token: str,\n","            testSplit: float = 0.2,\n","            outputDir: str = \"./results\",\n","            modelName: str = \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n","            newModelName: str = \"Llama-8B-FT\"\n","        ):\n","\n","        self.modelName = modelName\n","        self.newModelName = newModelName\n","        self.trainingData = trainingData\n","        self.token = token\n","        self.testSplit = testSplit\n","        self.outputDir = outputDir\n","        self.newModelName = newModelName\n","\n","        self.model, self.tokenizer = self.loadModel()\n","\n","        self.dataset = self.loadDataset()\n","\n","        self.loraConfig = self.configLora()\n","\n","    def loadModel(self):\n","        tokenizer = AutoTokenizer.from_pretrained(\n","            self.modelName,\n","            token=self.token\n","        )\n","        tokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN})\n","        tokenizer.padding_side = \"right\"\n","\n","        quantization = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16,\n","        )\n","\n","        model = AutoModelForCausalLM.from_pretrained(\n","            self.modelName,\n","            quantization_config=quantization,\n","            token=self.token,\n","            device_map=\"auto\"\n","        )\n","        model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\n","\n","        return model, tokenizer\n","\n","    def loadDataset(self):\n","        data = pd.read_csv(self.trainingData)\n","        data[\"text\"] = data.apply(self.format_example, axis=1)\n","\n","        train, temp = train_test_split(data, test_size=self.testSplit)\n","        val, test = train_test_split(temp, test_size=self.testSplit)\n","\n","        train.to_json(\"train.json\", orient=\"records\", lines=True)\n","        val.to_json(\"val.json\", orient=\"records\", lines=True)\n","        test.to_json(\"test.json\", orient=\"records\", lines=True)\n","\n","        dataset = load_dataset(\"json\", data_files={\n","            \"train\": \"train.json\",\n","            \"validation\": \"val.json\",\n","            \"test\": \"test.json\"\n","        })\n","\n","        return dataset\n","\n","    def configLora(self):\n","        lora_config = LoraConfig(\n","            r=8,\n","            lora_alpha=16,\n","            target_modules=[\n","                \"self_attn.q_proj\",\n","                \"self_attn.k_proj\",\n","                \"self_attn.v_proj\",\n","                \"self_attn.o_proj\",\n","                \"mlp.gate_proj\",\n","                \"mlp.up_proj\",\n","                \"mlp.down_proj\",\n","            ],\n","            lora_dropout=0.05,\n","            bias=\"none\",\n","            task_type=\"CAUSAL_LM\"\n","        )\n","\n","        self.model = prepare_model_for_kbit_training(self.model)\n","        self.model = get_peft_model(self.model, lora_config)\n","\n","        print(f\"{self.model.print_trainable_parameters()} can be trained\")\n","\n","        return lora_config\n","\n","    def finetune(self):\n","        sftConfig = SFTConfig(\n","            output_dir=self.outputDir,\n","            dataset_text_field=\"text\",\n","            max_seq_length=512,\n","            num_train_epochs=3,\n","            per_device_train_batch_size=2,\n","            per_device_eval_batch_size=2,\n","            gradient_accumulation_steps=16,\n","            optim=\"paged_adamw_32bit\",\n","            evaluation_strategy=\"steps\",\n","            eval_steps=0.2,\n","            save_steps=0.2,\n","            logging_steps=10,\n","            learning_rate=2e-4,\n","            fp16=True,\n","            save_strategy=\"steps\",\n","            warmup_ratio=0.1,\n","            save_total_limit=2,\n","            lr_scheduler_type=\"constant\",\n","            report_to=\"tensorboard\",\n","            save_safetensors=True,\n","            dataset_kwargs={\n","                \"add_special_tokens\": False,\n","                \"append_concat_token\": False\n","            }\n","        )\n","\n","        trainer = SFTTrainer(\n","            model=self.model,\n","            args=sftConfig,\n","            train_dataset=self.dataset[\"train\"],\n","            eval_dataset=self.dataset[\"validation\"],\n","            peft_config=self.loraConfig,\n","            tokenizer=self.tokenizer\n","        )\n","\n","        trainer.train()\n","\n","        trainer.save_model(self.newModelName)\n","\n","        self.saveNewModel()\n","\n","    def saveNewModel(self):\n","        tokenizer = AutoTokenizer.from_pretrained(\n","            self.newModelName,\n","            token=self.token\n","        )\n","\n","        model = AutoModelForCausalLM.from_pretrained(\n","            self.modelName,\n","            token=self.token,\n","            torch_dtype=torch.float16,\n","            device_map=\"auto\"\n","        )\n","\n","        model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\n","        model = PeftModel.from_pretrained(model, self.newModelName)\n","        model.merge_and_unload()\n","\n","        model.push_to_hub(self.newModelName, max_shard_size=\"5GB\")\n","        tokenizer.push_to_hub(self.newModelName)\n","\n","    def format_example(self, row: dict):\n","        messages = [\n","            {\n","                \"role\": \"system\",\n","                \"content\": \"IMPORT THIS\"\n","            },\n","            {\n","                \"role\": \"user\",\n","                \"content\": row[\"Question\"]\n","            },\n","            {\n","                \"role\": \"assistant\",\n","                \"content\": row[\"Answer\"]\n","            }\n","        ]\n","        return self.tokenizer.apply_chat_template(messages, tokenize=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T01:52:02.309759Z","iopub.status.busy":"2024-09-25T01:52:02.309392Z","iopub.status.idle":"2024-09-25T01:52:02.319580Z","shell.execute_reply":"2024-09-25T01:52:02.318607Z","shell.execute_reply.started":"2024-09-25T01:52:02.309722Z"},"trusted":true},"outputs":[],"source":["# %pip install gdown"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T01:52:02.321353Z","iopub.status.busy":"2024-09-25T01:52:02.320989Z","iopub.status.idle":"2024-09-25T01:52:02.329509Z","shell.execute_reply":"2024-09-25T01:52:02.328467Z","shell.execute_reply.started":"2024-09-25T01:52:02.321316Z"},"trusted":true},"outputs":[],"source":["# !gdown --id 1fry6rdlp1m67e6T1ODcntqc0M5tih01l"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T01:52:02.331051Z","iopub.status.busy":"2024-09-25T01:52:02.330713Z","iopub.status.idle":"2024-09-25T01:52:02.338458Z","shell.execute_reply":"2024-09-25T01:52:02.337472Z","shell.execute_reply.started":"2024-09-25T01:52:02.331017Z"},"trusted":true},"outputs":[],"source":["# ft = Finetune(\n","#     trainingData=\"Aptitude.csv\",\n","#     token=\"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\"\n","# )\n","\n","# ft.finetune()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T01:52:02.340101Z","iopub.status.busy":"2024-09-25T01:52:02.339801Z","iopub.status.idle":"2024-09-25T01:52:02.348195Z","shell.execute_reply":"2024-09-25T01:52:02.347218Z","shell.execute_reply.started":"2024-09-25T01:52:02.340068Z"},"trusted":true},"outputs":[],"source":["NEW_MODEL = \"Llama-8B-FT\"\n","MODEL_NAME = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T01:52:02.349952Z","iopub.status.busy":"2024-09-25T01:52:02.349440Z","iopub.status.idle":"2024-09-25T01:54:56.668913Z","shell.execute_reply":"2024-09-25T01:54:56.667305Z","shell.execute_reply.started":"2024-09-25T01:52:02.349889Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    NEW_MODEL,\n","    token=\"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\"\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    token=\"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\",\n","    torch_dtype=torch.float16,\n","    device_map=\"cuda\"\n",")\n","\n","model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\n","model = PeftModel.from_pretrained(model, NEW_MODEL)\n","model.merge_and_unload()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T01:54:56.669823Z","iopub.status.idle":"2024-09-25T01:54:56.670282Z","shell.execute_reply":"2024-09-25T01:54:56.670075Z","shell.execute_reply.started":"2024-09-25T01:54:56.670054Z"},"trusted":true},"outputs":[],"source":["model.push_to_hub(\"crackthejob/aptitudeLLM\", max_shard_size=\"5GB\")\n","tokenizer.push_to_hub(\"crackthejob/aptitudeLLM\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T02:06:07.497442Z","iopub.status.busy":"2024-09-25T02:06:07.496976Z","iopub.status.idle":"2024-09-25T02:06:26.087994Z","shell.execute_reply":"2024-09-25T02:06:26.086470Z","shell.execute_reply.started":"2024-09-25T02:06:07.497400Z"},"trusted":true},"outputs":[],"source":["%pip install pydrive"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T02:06:26.090757Z","iopub.status.busy":"2024-09-25T02:06:26.090328Z","iopub.status.idle":"2024-09-25T02:06:26.412682Z","shell.execute_reply":"2024-09-25T02:06:26.410608Z","shell.execute_reply.started":"2024-09-25T02:06:26.090701Z"},"trusted":true},"outputs":[],"source":["from pydrive.drive import GoogleDrive \n","from pydrive.auth import GoogleAuth \n","import os \n","   \n","gauth = GoogleAuth() \n","  \n","gauth.LocalWebserverAuth()        \n","drive = GoogleDrive(gauth)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T02:05:50.566506Z","iopub.status.busy":"2024-09-25T02:05:50.566101Z","iopub.status.idle":"2024-09-25T02:05:50.576930Z","shell.execute_reply":"2024-09-25T02:05:50.575697Z","shell.execute_reply.started":"2024-09-25T02:05:50.566463Z"},"trusted":true},"outputs":[],"source":["import os\n","os.listdir(\".\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for x in os.listdir(path): \n","   \n","    f = drive.CreateFile({'title': x}) \n","    f.SetContentFile(os.path.join(path, x)) \n","    f.Upload() \n","  \n","    # Due to a known bug in pydrive if we  \n","    # don't empty the variable used to \n","    # upload the files to Google Drive the \n","    # file stays open in memory and causes a \n","    # memory leak, therefore preventing its  \n","    # deletion \n","    f = None"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T02:12:35.949656Z","iopub.status.busy":"2024-09-25T02:12:35.948368Z","iopub.status.idle":"2024-09-25T02:12:35.959618Z","shell.execute_reply":"2024-09-25T02:12:35.958127Z","shell.execute_reply.started":"2024-09-25T02:12:35.949594Z"},"trusted":true},"outputs":[],"source":["import os\n","import subprocess\n","from IPython.display import FileLink, display\n","\n","def download_file(path, download_file_name):\n","    os.chdir('/kaggle/working/')\n","    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n","    command = f\"zip {zip_name} {path} -r\"\n","    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n","    if result.returncode != 0:\n","        print(\"Unable to run zip command!\")\n","        print(result.stderr)\n","        return\n","    display(FileLink(f'{download_file_name}.zip'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T02:13:22.575093Z","iopub.status.busy":"2024-09-25T02:13:22.574592Z","iopub.status.idle":"2024-09-25T02:13:55.776344Z","shell.execute_reply":"2024-09-25T02:13:55.775017Z","shell.execute_reply.started":"2024-09-25T02:13:22.575048Z"},"trusted":true},"outputs":[],"source":["download_file(\"results\", \"results\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30776,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
