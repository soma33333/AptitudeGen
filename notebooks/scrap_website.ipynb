{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac7cc3-17f2-4058-8207-623f6814b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def scrape_questions(url_template, num_sections, num_pages):\n",
    "    all_questions = []\n",
    "\n",
    "    for section in range(1, num_sections + 1):\n",
    "        for page in range(1, num_pages + 1):\n",
    "            url = url_template.format(section, page)\n",
    "            print(f\"Scraping section {section}, page {page}...\") \n",
    "\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status() \n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # Get all question blocks\n",
    "                question_blocks = soup.find_all('article', class_='question single-question question-type-normal')\n",
    "\n",
    "                for question_block in question_blocks:\n",
    "                    # Locate the question text\n",
    "                    question_tag = question_block.find('div', class_='question-main')\n",
    "                    option_paragraphs = question_block.find_all('p')  \n",
    "                    \n",
    "                   \n",
    "                    correct_option = None\n",
    "\n",
    "                    answer_container = question_block.find('div', class_='answer_container')\n",
    "                    if answer_container:\n",
    "                        answer_text = answer_container.find('strong')\n",
    "                        if answer_text:\n",
    "                            correct_option = answer_text.text.strip().split(\" \")[-1]  \n",
    "\n",
    "                    if question_tag:\n",
    "                        question = question_tag.text.strip()\n",
    "                        options = []\n",
    "                        for p in option_paragraphs:\n",
    "                            labels = p.find_all('label')\n",
    "                            if len(labels) >= 2: \n",
    "                                option_letter = labels[0].text.strip() \n",
    "                                option_value = labels[1].text.strip()  \n",
    "                                options.append(f\"{option_letter}{option_value}\")\n",
    "\n",
    "                       \n",
    "                        question_data = {\n",
    "                            \"Question\": question,\n",
    "                            \"opt1\": options[0] if len(options) > 0 else None,\n",
    "                            \"opt2\": options[1] if len(options) > 1 else None,\n",
    "                            \"opt3\": options[2] if len(options) > 2 else None,\n",
    "                            \"opt4\": options[3] if len(options) > 3 else None,\n",
    "                            \"opt5\": options[4] if len(options) > 4 else None,\n",
    "                            \"correct_answer\": correct_option,\n",
    "                        }\n",
    "\n",
    "                        all_questions.append(question_data)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request failed for section {section}, page {page}: {e}\")\n",
    "\n",
    "    return all_questions\n",
    "\n",
    "\n",
    "url_template = 'https://www.examveda.com/competitive-english/practice-mcq-question-on-ordering-of-sentences/?section={}&page={}'\n",
    "num_sections = 3\n",
    "num_pages = 10   \n",
    "\n",
    "output_file = 'verbal_dataset.csv'\n",
    "scraped_questions = scrape_questions(url_template, num_sections, num_pages)\n",
    "df_new = pd.DataFrame(scraped_questions)\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    df_existing = pd.read_csv(output_file)\n",
    "    \n",
    "    existing_questions_set = set(df_existing['Question'])\n",
    "    df_new = df_new[~df_new['Question'].isin(existing_questions_set)]\n",
    "    df_combined = pd.concat([df_existing, df_new], ignore_index=True) if not df_new.empty else df_existing\n",
    "else:\n",
    "    df_combined = df_new\n",
    "\n",
    "total_questions = len(df_combined)\n",
    "print(f\"Total questions in dataset: {total_questions}\")\n",
    "if not df_combined.empty:\n",
    "    df_combined.to_csv(output_file, index=False)\n",
    "    print(f\"Questions saved to '{output_file}'\")\n",
    "else:\n",
    "    print(\"No data to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dbce18-4551-4a1b-bd1c-008fc316f2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
